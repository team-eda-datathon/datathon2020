{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bad_model.ipynb","provenance":[],"authorship_tag":"ABX9TyMiEl7n0JziMXwSa6915yuq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kiaQOBVKTo93"},"source":["* Inference using TF-IDF weighted vectors\n","\n","* Matching & document similarity calculation using TS-SS method (details in research paper attached to this repo)\n"]},{"cell_type":"code","metadata":{"id":"KfQTcTU3QnY2","executionInfo":{"status":"ok","timestamp":1601565149786,"user_tz":-480,"elapsed":1389,"user":{"displayName":"Ho Yin HO","photoUrl":"","userId":"15101021176076886258"}},"outputId":"3150394f-36cb-4422-c105-63205181df7e","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from __future__ import unicode_literals\n","from gensim.summarization import keywords\n","import pandas as pd\n","import math\n","import nltk\n","import string\n","import matplotlib.pyplot as plt\n","from nltk.stem.porter import PorterStemmer\n","import unicodedata\n","import nltk\n","nltk.download('stopwords')\n","import gensim\n","import logging"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NGfb3YLMQpU7"},"source":["df = pd.read_csv('data.csv')\n","selected_df = df[['job_description','company_name','job_title','category']]\n","selected_df = selected_df.dropna()\n","selected_df['new_job_description'] = df['job_description'] + df['category'] \n","jds = selected_df['new_job_description'].tolist()\n","companies = selected_df['company_name'].tolist()\n","positions = selected_df['job_title'].tolist() #[position of job]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fyCCGBRZn9C"},"source":["class MyCountVectorizer:\n","    def __init__(self, docs):\n","        self.corpus = self.normalize_corpus(docs)\n","        self.make_features()\n","        self.make_matrix()\n","        \n","    def normalize_corpus(self, docs):    \n","        table = str.maketrans(string.punctuation, \n","                                 len(string.punctuation) * ' ')\n","        norm_docs = []\n","        for doc_raw in docs:\n","            doc = filter(lambda x: x in string.printable, doc_raw)\n","            '''\n","            doc = ''\n","            for x in doc_raw:\n","                if x in string.printable:\n","                    doc += x\n","            '''\n","            doc = str(doc).translate(table).lower()\n","            norm_docs.append(doc)\n","        #self.corpus = norm_docs\n","        return norm_docs\n","        \n","    def make_features(self):\n","        ''' create vocabulary set from the corpus '''\n","        stopwords = nltk.corpus.stopwords.words('english')\n","        self.features = set()\n","        for doc in self.corpus:\n","            for word in doc.split():\n","                if word not in stopwords:\n","                    self.features.add(word)\n","        #self.features = set([word for doc in self.corpus for word in doc.split() if word not in stopwords])\n","        self.features = sorted(list(self.features))\n","\n","    def make_matrix(self):\n","        self.matrix = []\n","        for doc in self.corpus:\n","            doc_vec = []\n","            for word in self.features:\n","                tf = self.term_freq(word, doc)\n","                doc_vec.append(tf)\n","            self.matrix.append(doc_vec)\n","\n","    def term_freq(self, term, document):\n","        words = document.split()\n","        count = 0\n","        for word in words:\n","            if word == term:\n","                count += 1\n","        return count\n","    \n","    def print_matrix(self):\n","        for vec in self.matrix:\n","            print(vec)\n","\n","    def get_matrix(self):\n","        return self.matrix\n","    \n","    def get_features(self):\n","        return self.features\n","    \n","    def get_density(self):\n","        ''' get the density (# of non-zero elements / # all elements )'''\n","        counter = 0\n","        total = 0\n","        for row in self.matrix:\n","            for item in row:\n","                if item != 0:\n","                    counter += 1\n","                total += 1\n","        return 1.0 * counter / total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jlu1vFjuZqd2"},"source":["class MyTfIdfVectorizer(MyCountVectorizer):\n","    ''' inherits from MyCountVectorizer'''\n","\n","    def make_matrix(self):\n","        'overriding method'\n","        self.matrix = []\n","        for doc in self.corpus:\n","            doc_vec = []\n","            for word in self.features:\n","                tf = self.term_freq(word, doc)\n","                idf = self.inverse_document_freq(word)\n","                doc_vec.append(tf * idf)\n","            #self.matrix.append(doc_vec)\n","            total = sum(doc_vec)\n","            doc_vec_norm = [i/total for i in doc_vec]\n","            self.matrix.append(doc_vec_norm)\n","\n","    def inverse_document_freq(self, term):\n","        doc_count = 0\n","        for document in self.corpus:\n","            term_count = self.term_freq(term, document)\n","            if term_count > 0:\n","                doc_count += 1\n","        return math.log( 1.0 * len(self.corpus) / doc_count)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Digf6SdeZusD"},"source":["resume = 'resume.txt'\n","with open(resume,'r') as f:\n","      resume = f.read()\n","jds.append(resume)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5csFBaXaMnZ"},"source":["myvec = MyTfIdfVectorizer(jds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlL4XfRabduH"},"source":["logging.basicConfig(\n","    format='%(asctime)s : %(levelname)s : %(message)s', \n","    level=logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZnl4-Onb9l0","executionInfo":{"status":"ok","timestamp":1601565309330,"user_tz":-480,"elapsed":160879,"user":{"displayName":"Ho Yin HO","photoUrl":"","userId":"15101021176076886258"}},"outputId":"b81364e2-36fa-4679-b78b-2dd7c7d30ed4","colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["model = gensim.models.KeyedVectors.load_word2vec_format(\n","    \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \n","    binary=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-01 15:13:18,114 : INFO : loading projection weights from https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n","/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n","2020-10-01 15:15:08,497 : INFO : loaded (3000000, 300) matrix from https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UnqgwI9lfZij"},"source":["stopwords = nltk.corpus.stopwords.words('english')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6CN2SDsff50"},"source":["imp = ['java']\n","p = string.punctuation\n","d = string.digits\n","table_p = str.maketrans(p, len(p) * \" \")\n","table_d = str.maketrans(d, len(d) * \" \")\n","vec = []\n","for jd in jds:\n","    x = jd.translate(table_p)\n","    y = x.translate(table_d)\n","    jd_vector = []\n","    i = 0\n","    for word in y.split():\n","        if word.lower() not in stopwords and len(word)>1 and word not in imp:\n","            try:\n","                x = model[word]\n","                idx = myvec.get_features().index(word)\n","                z = myvec.get_matrix()[i][idx]\n","                lst = [a * z for a in x]\n","                jd_vector.append(lst)\n","            except:\n","                continue\n","        else:\n","            try:\n","                x = model[word]\n","                lst = [a * 2 for a in x]\n","                jd_vector.append(lst)\n","            except:\n","                continue\n","    i+=1\n","    vec.append(jd_vector)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofPVaJOjfhs3"},"source":["mean_vec = []\n","for j in vec:\n","    mean = []\n","    for i in range(300):\n","        accum =0\n","        for word in j:\n","            accum += word[i]\n","        mean.append(1.0*accum/len(word))\n","    mean_vec.append(mean)\n","data = mean_vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ld3_ixyehC7H","executionInfo":{"status":"ok","timestamp":1601565605974,"user_tz":-480,"elapsed":457491,"user":{"displayName":"Ho Yin HO","photoUrl":"","userId":"15101021176076886258"}},"outputId":"de8d30a0-d1b7-452f-eb39-f1590bf38283","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from scipy.spatial import distance\n","cos_dist =[]\n","for vec in data[:-1]:\n","  cos_dist.append(float(distance.cosine(vec,data[-1])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n","  dist = 1.0 - uv / np.sqrt(uu * vv)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"npW0Bekbfunb"},"source":["ps = PorterStemmer()\n","key_list =[]\n","\n","for jd in jds[:-1]:\n","    key = ''\n","    w = set()\n","    for word in keywords(jd).split('\\n'):\n","        w.add(ps.stem(word))\n","    for x in w:\n","        key += '{} '.format(x)\n","    key_list.append(key)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFIsQmkCfykI"},"source":["summary = pd.DataFrame({\n","        'Company': companies,\n","        'Postition': positions,\n","        'Cosine Distances': cos_dist,\n","        #'Keywords': key_list,\n","        'Job Description': jds[:-1]\n","    })\n","z = summary.sort_values(by= 'Cosine Distances', ascending=False)\n","#z.to_csv('Summary.csv',encoding=\"utf-8\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uzuXa1dNhsJM","executionInfo":{"status":"ok","timestamp":1601565793608,"user_tz":-480,"elapsed":13,"user":{"displayName":"Ho Yin HO","photoUrl":"","userId":"15101021176076886258"}},"outputId":"b6da8bb9-1a49-4718-8c83-140f3047f5ec","colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["z.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Company</th>\n","      <th>Postition</th>\n","      <th>Cosine Distances</th>\n","      <th>Job Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1596</th>\n","      <td>Private Advertiser</td>\n","      <td>Owner Drivers</td>\n","      <td>0.883422</td>\n","      <td>Metrans Late-model white 1&amp;2T Vans &amp; Trays 4-1...</td>\n","    </tr>\n","    <tr>\n","      <th>1615</th>\n","      <td>CKC Cabinets pty ltd</td>\n","      <td>Cabinet maker</td>\n","      <td>0.740032</td>\n","      <td>We are seeking open minded people who are inte...</td>\n","    </tr>\n","    <tr>\n","      <th>2399</th>\n","      <td>Private Advertiser</td>\n","      <td>Carpenter/Concreter OFFSIDER</td>\n","      <td>0.738509</td>\n","      <td>POSITION VACANT Carpenter/Concreter OFFSIDER S...</td>\n","    </tr>\n","    <tr>\n","      <th>2948</th>\n","      <td>Private Advertiser</td>\n","      <td>Security Guards</td>\n","      <td>0.707050</td>\n","      <td>Full Time and Casual Work. Must be available f...</td>\n","    </tr>\n","    <tr>\n","      <th>1261</th>\n","      <td>Hukarere Girls' College</td>\n","      <td>Weekend Activities Supervisor</td>\n","      <td>0.706251</td>\n","      <td>Hukarere Girls' College Hostel Weekend Activit...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      Company  ...                                    Job Description\n","1596       Private Advertiser  ...  Metrans Late-model white 1&2T Vans & Trays 4-1...\n","1615     CKC Cabinets pty ltd  ...  We are seeking open minded people who are inte...\n","2399       Private Advertiser  ...  POSITION VACANT Carpenter/Concreter OFFSIDER S...\n","2948       Private Advertiser  ...  Full Time and Casual Work. Must be available f...\n","1261  Hukarere Girls' College  ...  Hukarere Girls' College Hostel Weekend Activit...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":37}]}]}